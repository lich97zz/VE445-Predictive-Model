Training...
epoch: 0 | train loss: 0.3979 | valid accuracy: 0.70
EPOCH TIME(sec): 304.47
ESTIMATED TIME(min): 101.5
epoch: 1 | train loss: 0.2922 | valid accuracy: 0.73
epoch: 2 | train loss: 0.2576 | valid accuracy: 0.75
epoch: 3 | train loss: 0.2038 | valid accuracy: 0.76
epoch: 4 | train loss: 0.1380 | valid accuracy: 0.76
epoch: 5 | train loss: 0.1602 | valid accuracy: 0.76
epoch: 6 | train loss: 0.1468 | valid accuracy: 0.77
epoch: 7 | train loss: 0.0651 | valid accuracy: 0.76
epoch: 8 | train loss: 0.1222 | valid accuracy: 0.76
epoch: 9 | train loss: 0.0874 | valid accuracy: 0.77
epoch: 10 | train loss: 0.1312 | valid accuracy: 0.78
epoch: 11 | train loss: 0.1314 | valid accuracy: 0.79
epoch: 12 | train loss: 0.0523 | valid accuracy: 0.79
epoch: 13 | train loss: 0.0323 | valid accuracy: 0.80
epoch: 14 | train loss: 0.0296 | valid accuracy: 0.80
epoch: 15 | train loss: 0.0838 | valid accuracy: 0.80
epoch: 16 | train loss: 0.0386 | valid accuracy: 0.81
epoch: 17 | train loss: 0.0246 | valid accuracy: 0.81
epoch: 18 | train loss: 0.0129 | valid accuracy: 0.81
epoch: 19 | train loss: 0.0390 | valid accuracy: 0.82
result_A.R.P: (0.744923, 0.59600616, 0.24525917)

def net(onehots_shape,lr_):  # [73,398]
    onehots_shape = list(onehots_shape)
    input = tf.placeholder(tf.float32, [None] + onehots_shape, name='input')
    input = tf.reshape(input, [-1] + onehots_shape + [1])
    # input = tf.reshape(input, [None, 73, 398, 1])
    conv_num = 32
    label = tf.placeholder(tf.int32, [None], name='label')
    label = tf.one_hot(label, 2)   
    conv1 = tf.keras.layers.Conv2D(conv_num, 5, 1, 'same', activation=tf.nn.relu)(input)
    pool1 = tf.keras.layers.MaxPool2D(2, 2)(conv1)
    conv2 = tf.keras.layers.Conv2D(conv_num, 3, (1, 2), padding='same', activation=tf.nn.relu)(pool1)
    pool2 = tf.keras.layers.MaxPool2D(2, 2)(conv2)
    conv3 = tf.keras.layers.Conv2D(conv_num, 3, 3, padding='same', activation=tf.nn.relu)(pool2)
    conv4 = tf.keras.layers.Conv2D(conv_num, 3, 3, padding='same', activation=tf.nn.relu)(conv3)    
    pool3 = tf.keras.layers.MaxPool2D(2, 2)(conv4)
    
    flat = tf.reshape(pool3, [-1, 1*3*conv_num])
    output1 = tf.keras.layers.Dense(16, name='output1')(flat)
    output2 = tf.keras.layers.Dense(16, name='output2')(output1)
    output = tf.keras.layers.Dense(2, name='output')(output2)
    loss = tf.losses.softmax_cross_entropy(onehot_labels=label, logits=output) 

    train_op = tf.train.AdamOptimizer(lr_).minimize(loss)
    accuracy = tf.metrics.accuracy(  # return (acc, update_op), and create 2 local variables
        labels=tf.argmax(label, axis=1), predictions=tf.argmax(output, axis=1), )[1]
    recall = tf.metrics.recall(  # return (acc, update_op), and create 2 local variables
        labels=tf.argmax(label, axis=1), predictions=tf.argmax(output, axis=1), )[1]
    precision = tf.metrics.precision(  # return (acc, update_op), and create 2 local variables
        labels=tf.argmax(label, axis=1), predictions=tf.argmax(output, axis=1), )[1]

    init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())
    return init_op, train_op, loss, accuracy, recall, precision

